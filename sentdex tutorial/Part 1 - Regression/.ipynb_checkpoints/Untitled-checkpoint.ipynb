{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression Tutorial\n",
    "\n",
    "#Regression -> Take continuous data and figure out the best function for the data.\n",
    "#simple Regression -> Linear Equation (y=mx+b)\n",
    "#Regression -> find y & x. E.g. used on stock market prediction\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import quandl #function library yang gunanya kayak buat kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open    High     Low    Close      Volume  Ex-Dividend  \\\n",
      "Date                                                                   \n",
      "2004-08-19  100.01  104.06   95.96  100.335  44659000.0          0.0   \n",
      "2004-08-20  101.01  109.08  100.50  108.310  22834300.0          0.0   \n",
      "2004-08-23  110.76  113.48  109.05  109.400  18256100.0          0.0   \n",
      "2004-08-24  111.24  111.60  103.57  104.870  15247300.0          0.0   \n",
      "2004-08-25  104.76  108.00  103.88  106.000   9188600.0          0.0   \n",
      "\n",
      "            Split Ratio  Adj. Open  Adj. High   Adj. Low  Adj. Close  \\\n",
      "Date                                                                   \n",
      "2004-08-19          1.0  50.159839  52.191109  48.128568   50.322842   \n",
      "2004-08-20          1.0  50.661387  54.708881  50.405597   54.322689   \n",
      "2004-08-23          1.0  55.551482  56.915693  54.693835   54.869377   \n",
      "2004-08-24          1.0  55.792225  55.972783  51.945350   52.597363   \n",
      "2004-08-25          1.0  52.542193  54.167209  52.100830   53.164113   \n",
      "\n",
      "            Adj. Volume  \n",
      "Date                     \n",
      "2004-08-19   44659000.0  \n",
      "2004-08-20   22834300.0  \n",
      "2004-08-23   18256100.0  \n",
      "2004-08-24   15247300.0  \n",
      "2004-08-25    9188600.0  \n"
     ]
    }
   ],
   "source": [
    "df = quandl.get('WIKI/GOOGL')\n",
    "print(df.head())\n",
    "\n",
    "#What we want are features that have some things to do with our goal\n",
    "#So many data -> but we do not need all of the data\n",
    "#P.S. -> Adj is when stock is split into two 1000 to two 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Close    HL_PCT  PCT_change  Adj. Volume\n",
      "Date                                                     \n",
      "2004-08-19   50.322842  3.712563    0.324968   44659000.0\n",
      "2004-08-20   54.322689  0.710922    7.227007   22834300.0\n",
      "2004-08-23   54.869377  3.729433   -1.227880   18256100.0\n",
      "2004-08-24   52.597363  6.417469   -5.726357   15247300.0\n",
      "2004-08-25   53.164113  1.886792    1.183658    9188600.0\n"
     ]
    }
   ],
   "source": [
    "##Grab features\n",
    "\n",
    "df_data = df[['Adj. Open','Adj. High','Adj. Low','Adj. Close','Adj. Volume']]\n",
    "#Margin between high and low tells volatility of the market, Margin between Open&close shows how much stock price increase/decrease\n",
    "#Volume shows how many trade that day\n",
    "#Shows that each collumn has relation with each other\n",
    "\n",
    "#HL_PCT -> High low Percentage\n",
    "\n",
    "df_data['HL_PCT'] = (df_data['Adj. High']-df_data['Adj. Close']) / df_data['Adj. Close']*100\n",
    "df_data['PCT_change'] = (df_data['Adj. Close']-df_data['Adj. Open']) / df_data['Adj. Open']*100\n",
    "\n",
    "df_Regressed = df_data[['Adj. Close','HL_PCT','PCT_change','Adj. Volume']]\n",
    "\n",
    "print(df_Regressed.head()) #Take data that we need only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Close    HL_PCT  PCT_change  Adj. Volume Forecast_date  \\\n",
      "Date                                                                      \n",
      "2004-08-19   50.322842  3.712563    0.324968   44659000.0    2004-08-25   \n",
      "2004-08-20   54.322689  0.710922    7.227007   22834300.0    2004-08-26   \n",
      "2004-08-23   54.869377  3.729433   -1.227880   18256100.0    2004-08-27   \n",
      "2004-08-24   52.597363  6.417469   -5.726357   15247300.0    2004-08-30   \n",
      "2004-08-25   53.164113  1.886792    1.183658    9188600.0    2004-08-31   \n",
      "\n",
      "                label  \n",
      "Date                   \n",
      "2004-08-19  53.164113  \n",
      "2004-08-20  54.122070  \n",
      "2004-08-23  53.239345  \n",
      "2004-08-24  51.162935  \n",
      "2004-08-25  51.343492  \n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "##Labels. Simplenya feature itu input, label itu outputnya\n",
    "\n",
    "df_Regressed['Forecast_date'] = df_Regressed.index #since Date is index, we need to copy index into a collumn\n",
    "forecast_col = 'Adj. Close'\n",
    "df_Regressed.fillna(-9999, inplace=True) #fill NaN value with -99,999, and inplace True. This is used because machine learning cannot process NaN value.\n",
    "\n",
    "forecast_out = int(math.ceil(0.1*len(df))) #round length of df*x (x in this case is 0.1. This is used to predict x percent from the dataframe. \n",
    "\n",
    "df_Regressed['label'] = df_Regressed[forecast_col].shift(-forecast_out) #so by using this, the data will be shifted to up based on the x value in forecast_out\n",
    "df_Regressed['Forecast_date'].update(df_Regressed['Forecast_date'].shift(-forecast_out)) #so by using this, the data will be shifted to up based on the x value in forecast_out\n",
    "\n",
    "\n",
    "print (df_Regressed.head()) #note the forecast date is different than the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cross_validation' from 'sklearn' (C:\\Users\\jovan\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-87724fc26a57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;31m#will be able use array in py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[1;31m#Will use Scaling data -> So feature value will be between -1 & 1 so it can help will accuracy and processing speed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_validation\u001b[0m \u001b[1;31m#Shuffle data so that we dont have biased data and separate data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvm\u001b[0m \u001b[1;31m#to do regression and how simple it is on changing the algorithm we are using\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'cross_validation' from 'sklearn' (C:\\Users\\jovan\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#Define label and pass through classifier\n",
    "\n",
    "df = df_Regressed\n",
    "\n",
    "import numpy as np #will be able use array in py\n",
    "from sklearn import preprocessing #Will use Scaling data -> So feature value will be between -1 & 1 so it can help will accuracy and processing speed.\n",
    "from sklearn.model_selection import train_test_split\n",
    " #Shuffle data so that we dont have biased data and separate data\n",
    "from sklearn import svm #to do regression and how simple it is on changing the algorithm we are using\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#usually features will be x, labels will be y\n",
    "X = np.array(df.drop(['label'],1))\n",
    "y = np.array(df['Forecast_date','label'])\n",
    "\n",
    "X = preprocessing.scale(X) #Before you can put data through classifier, data needs to be scaled. Scaling is like normalized with other data points. TO get an optimal scaled data, data needs also to be scaled with other value, such as including it with our training data/other values.\n",
    "#disadvantage->adds processing time. Such as in high freq trading, this step is skipped\n",
    "\n",
    "X=X[:-forecast_out+1] #This is done to make sure that data in table is only data that has value after shifted\n",
    "df.dropna(inplace=True) #making sure no more null data aftar fillna\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#Cross validation will split X&Y into two different data. One used for training, other for testing\n",
    "#Training 80% of the data. The data is shuffled when training (ofc connected X and Y) and testing to get unbiased data\n",
    "\n",
    "#classifier \n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train) #fit->train\n",
    "cld.score(X_test,y_test) #testing buat tau akurasinya. Kenapa dipisah train,test? Train kayak latihan, test kayak ulangan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
